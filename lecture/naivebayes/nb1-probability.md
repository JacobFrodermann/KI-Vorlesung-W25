# Wiederholung Wahrscheinlichkeitstheorie

> [!NOTE]
>
> <details open>
>
> <summary><strong>üéØ TL;DR</strong></summary>
>
> Diese Sitzung ist eine (relativ oberfl√§chliche)
> Einf√ºhrung/Wiederholung in die/der Grundlagen der
> Wahrscheinlichkeitstheorie.
>
> Wir schauen uns die m√∂glichen Ausg√§nge eines Zufallsexperiments an
> (‚ÄúEreignisse‚Äù). Wenn diese Ereignisse sich gegenseitig ausschlie√üen
> und alle denkbaren Ergebnisse abdecken, dann nennt man diese
> Ereignisse auch **Elementarereignisse**. Die Wahrscheinlichkeit f√ºr
> ein Ereignis kann man angeben als Anzahl der m√∂glichen Ergebnisse, die
> f√ºr dieses Ereignis g√ºnstig sind, geteilt durch die Anzahl aller
> Ausg√§nge. √úber die Kolmogorov Axiome bekommt man die typischen
> Rechenregel f√ºr die Wahrscheinlichkeit.
>
> Man kann eine **Verbundwahrscheinlichkeit** $`P(A,B) = P(B,A)`$
> angeben, das ist die Wahrscheinlichkeit, dass $`A`$ und $`B`$
> gleichzeitig auftreten.
>
> Die **bedingte** Wahrscheinlichkeit f√ºr $`A`$ gegeben $`B`$ ist
> $`P(A|B)`$ und berechnet sich $`P(A|B) = \frac{P(A,B)}{P(B)}`$.
>
> Daraus kann man die **Bayes-Regel** ableiten:
> ``` math
> P(A|B) = \frac{P(B|A)P(A)}{P(B)}
> ```
> Dabei nennt man
>
> - $`P(A)`$ **‚ÄúPrior‚Äù** oder **‚ÄúA-priori-Wahrscheinlichkeit‚Äù** (die
>   Wahrscheinlichkeit f√ºr $`A`$ ohne weiteres Wissen),
> - $`P(B|A)`$ **‚ÄúLikelihood‚Äù** (Wie wahrscheinlich ist das Auftreten
>   von $`B`$, gegeben $`A`$?),
> - $`P(A|B)`$ **‚ÄúPosterior‚Äù** oder
>   **‚ÄúA-posteriori-Wahrscheinlichkeit‚Äù** (Wie wahrscheinlich ist $`A`$,
>   wenn $`B`$ eingetreten ist?), und
> - $`P(B)`$ ist ein Normierungsfaktor (Wie wahrscheinlich ist $`B`$ an
>   sich?).
>
> </details>
>
> <details>
>
> <summary><strong>üé¶ Videos</strong></summary>
>
> - [VL Wahrscheinlichkeiten](https://youtu.be/p_Yy5rkl4CA)
>
> </details>

## Ereignisse und Wahrscheinlichkeit

**Hinweis**: Die folgende Darstellung zur Einf√ºhrung in die
Wahrscheinlichkeitstheorie dient dem Verst√§ndnis des Naive Bayes
Klassifikationsalgorithmus und ist teilweise eher oberfl√§chlich
gehalten. Sie kann und soll keine entsprechende mathematische Einf√ºhrung
ersetzen!

### Ereignisse

- **Ereignisse**
  $`\Omega = \lbrace \omega_1, \omega_2, \ldots, \omega_n \rbrace`$:
  endliche Menge der Ausg√§nge eines Zufallsexperiments

- **Elementarereignis**: Die $`\omega_i \in \Omega`$

  - decken *alle* m√∂glichen Versuchsergebnisse ab, und
  - schlie√üen sich gegenseitig aus

### Regeln

- Wenn $`A`$ und $`B`$ Ereignisse sind, dann auch $`A \cup B`$
- $`\Omega`$ wird als **sicheres Ereignis** bezeichnet: Enth√§lt
  definitionsgem√§√ü **alle** Versuchsausg√§nge, d.h. *ein* in der Menge
  enthaltenes Ereignis *muss* auftreten
- Die leere Menge $`\emptyset`$ wird als **unm√∂gliches Ereignis**
  bezeichnet
- Die Variablen $`A`$ und $`B`$ hei√üen auch **Zufallsvariablen**

Im Rahmen dieser Veranstaltung betrachten wir nur diskrete
Zufallsvariablen mit endlichem Wertebereich!

### Wahrscheinlichkeit

- **Wahrscheinlichkeit**:

  Sei $`\Omega = \lbrace \omega_1, \omega_2, \ldots, \omega_n \rbrace`$
  endlich. Die Wahrscheinlichkeit $`P(A)`$ f√ºr ein Ereignis $`A`$ ist
  dann definiert als

  Man k√∂nnte auch schreiben: $`P(A) = \sum_{\omega \in A} P(\omega)`$

  *Hinweis*: Diese Definition von Wahrscheinlichkeit geht von gleich
  wahrscheinlichen Elementarereignissen aus! Die allgemeine Definition
  geht √ºber einen entsprechenden Grenzwert.

``` math
P(A) = \frac{|A|}{|\Omega|} =
\frac{\text{Anzahl der f√ºr A g√ºnstigen F√§lle}}{\text{Anzahl der m√∂glichen F√§lle}}
```

### Verteilung

Den Vektor mit den Wahrscheinlichkeiten aller Elementarereignisse nennt
man auch *Verteilung*.

Beispiel:
$`\mathbf{P}(A) = (P(A=1), P(A=2), \ldots, P(A=6)) = (1/6, 1/6, \ldots, 1/6)`$

*Hinweis*: Wir betrachten hier nur diskrete Zufallsvariablen. F√ºr
kontinuierliche Variablen wird die Verteilung mit Hilfe einer
**Dichtefunktion** dargestellt, beispielsweise der Gauss‚Äôschen Funktion.

### Beispiel

- Einmaliges W√ºrfeln mit einem Spielw√ºrfel:
  $`\Omega = \lbrace 1,2,3,4,5,6 \rbrace`$
- Elementarereignisse: $`\lbrace 1,2,3,4,5,6 \rbrace`$
- Das W√ºrfeln einer geraden Zahl ($`A = \lbrace 2,4,6 \rbrace`$) ist
  *kein* Elementarereignis, ebenso wie das W√ºrfeln einer Zahl kleiner 5
  ($`B = \lbrace 1,2,3,4 \rbrace`$), da
  $`A \cap B = \lbrace 2,4 \rbrace \ne \emptyset`$
- Wahrscheinlichkeit, eine 1 zu w√ºrfeln:
  $`P(A \in \lbrace 1 \rbrace) = P(A=1) = \frac{1}{6}`$. *Anmerkung*:
  Man schreibt statt $`P(A \in \lbrace 1 \rbrace)`$ oft einfach
  $`P(1)`$.
- Wahrscheinlichkeit, eine gerade Zahl zu w√ºrfeln:
  $`P(A \in \lbrace 2,4,6 \rbrace) = P(A=2 \vee A=4 \vee A=6) = \frac{|\lbrace 2,4,6 \rbrace|}{|\lbrace 1,2,3,4,5,6 \rbrace|} = \frac{3}{6} = 0.5`$

## Rechenregeln: Kolmogorov Axiome

Sei $`A`$ ein Ereignis, also $`A \subseteq \Omega`$:

- $`0 \le P(A) \le 1`$

- $`\Omega = \lbrace \omega_1, \omega_2, \ldots, \omega_n \rbrace`$:
  $`\sum_{i} P(\omega_i) = 1`$ (Normierungsbedingung: Summe √ºber die
  Wahrscheinlichkeiten aller Elementarereignisse ist immer 1)

- $`P(A \cup B) = P(A) + P(B) - P(A \cap B)`$

Daraus folgt (u.a.):

- $`P(\Omega) = 1`$
- $`P(\emptyset) = 0`$
- $`P(A) = 1- P(\neg A)`$

<!-- -->

- $`A`$ und $`B`$ *unabh√§ngig*: $`P(A \cup B) = P(A) + P(B)`$
- $`P(A \cap B)`$ ist leer, wenn $`A`$ und $`B`$ sich nicht √ºberlappen
- $`A \subseteq B`$: $`P(A) \le P(B)`$

## Verbundwahrscheinlichkeiten

``` math
P(A,B) = P(B,A) = \text{ Wahrscheinlichkeit, dass A und B gleichzeitig auftreten }
```

|                    | Halsschmerzen | $`\neg`$ Halsschmerzen |
|--------------------|---------------|------------------------|
| Schnupfen          | 0.04          | 0.06                   |
| $`\neg`$ Schnupfen | 0.01          | 0.89                   |

- $`P(S,H) = 0.04`$

Die Tabelle kann man so lesen: In 4 von 100 F√§llen tritt das Ereignis
‚ÄúSchnupfen‚Äù gleichzeitig mit dem Ereignis ‚ÄúHalsschmerzen‚Äù auf, in 6 von
100 F√§llen tritt ‚ÄúSchupfen‚Äù ohne Halsschmerzen auf. ‚Ä¶ In Summe kommt man
wieder auf 100 F√§lle (100 Prozent).

Nach diesen Zahlen liegt also die Verbundwahrscheinlichkeit f√ºr die
Ereignisse ‚ÄúSchnupfen‚Äù und ‚ÄúHusten‚Äù, d.h. $`P(S,H)`$, bei 4 Prozent.

**Hinweis**: Die gezeigten Zahlen und Zusammenh√§nge sind **fiktiv** und
dienen lediglich zur Verdeutlichung der Wahrscheinlichkeitsbegriffe!

## Bedingte Wahrscheinlichkeit

**Definition**: Bedingte Wahrscheinlichkeit f√ºr $`A`$ gegeben $`B`$:

``` math
P(A|B) = \frac{P(A,B)}{P(B)}
```

|                    | Halsschmerzen | $`\neg`$ Halsschmerzen |
|--------------------|---------------|------------------------|
| Schnupfen          | 0.04          | 0.06                   |
| $`\neg`$ Schnupfen | 0.01          | 0.89                   |

- $`P(\text{Schnupfen } | \text{ Halsschmerzen}) = \frac{P(S,H)}{P(H)} = \frac{0.04}{0.04+0.01} = 0.8`$
- $`P(\text{Halsschmerzen } | \text{ Schnupfen}) = \frac{P(H,S)}{P(S)} = \frac{0.04}{0.04+0.06} = 0.4`$

Wegen $`P(A|B) = \dfrac{P(A,B)}{P(B)}`$ ist
$`P(A,B) = P(A|B)P(B) = P(B|A)P(A)`$ (**Produkt-Regel**)!

## Marginalisierung

|                    | Halsschmerzen | $`\neg`$ Halsschmerzen | $`\sum`$ |
|--------------------|---------------|------------------------|----------|
| Schnupfen          | 0.04          | 0.06                   | *0.1*    |
| $`\neg`$ Schnupfen | 0.01          | 0.89                   | *0.9*    |
| $`\sum`$           | *0.05*        | *0.95*                 | *1*      |

$`P(S) = P(S,H) + P(S, \neg H)`$

Allgemein: Seien $`B_1, \ldots, B_n`$ Elementarereignisse mit
$`\bigcup_i B_i = \Omega`$. Dann ist
``` math
P(A) = \sum_i P(A,B_i) = \sum_i P(A|B_i)P(B_i)
```

Diesen Vorgang nennt man **Marginalisierung**. Die resultierende
Verteilung $`P(A)`$ nennt man auch *‚ÄúRandverteilung‚Äù*, da sie mit einer
Projektion eines Quaders auf eine Seitenfl√§che vergleichbar ist.

## Kettenregel

- **Produktregel**: Wegen $`P(A|B) = \dfrac{P(A,B)}{P(B)}`$ gilt
  $`P(A,B) = P(A|B)P(B)`$

<!-- -->

- Verallgemeinerung (**Kettenregel**):

``` math
\begin{eqnarray}
P(A_1,A_2,\ldots,A_n) &=& P(A_n,\ldots,A_2,A_1)\\
    & = & P(A_n|A_{n-1},\ldots,A_1)P(A_{n-1},\ldots,A_1)\\
    & = & P(A_n|A_{n-1},\ldots,A_1)P(A_{n-1}|A_{n-2},\ldots,A_1)P(A_{n-2},\ldots,A_1)\\
    & = & \ldots\\
    & = & P(A_n|A_{n-1},\ldots,A_1) \ldots P(A_2|A_1)P(A_1)\\
    & = & \prod_i P(A_i|A_1,\ldots,A_{i-1})
\end{eqnarray}
```

## Bayes-Regel

Bedingte Wahrscheinlichkeit: $`P(A,B) = P(A|B)P(B) = P(B|A)P(A)`$

``` math
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
```

- $`P(A)`$ nennt man **‚ÄúPrior‚Äù** oder **‚ÄúA-priori-Wahrscheinlichkeit‚Äù**
  (Das ist die Wahrscheinlichkeit f√ºr $`A`$ ohne weiteres Wissen)
- $`P(B|A)`$ nennt man **‚ÄúLikelihood‚Äù** (Wie wahrscheinlich ist das
  Auftreten von $`B`$, gegeben $`A`$?)
- $`P(A|B)`$ nennt man **‚ÄúPosterior‚Äù** oder
  **‚ÄúA-posteriori-Wahrscheinlichkeit‚Äù** (Wie wahrscheinlich ist $`A`$,
  wenn $`B`$ eingetreten ist?)
- $`P(B)`$ ist ein Normierungsfaktor

Wenn man (siehe sp√§ter: Naive Bayes Klassifikator) $`A`$ als Klasse und
$`B`$ als Daten betrachtet:

- $`P(A)`$: Wie wahrscheinlich ist eine bestimmte Klasse an sich
  (A-priori-Wahrscheinlichkeit der Klassen)?
- $`P(B|A)`$: Wie wahrscheinlich sind bestimmte Daten, gegeben die
  Klasse $`A`$? (Likelihood der Daten)
- $`P(A|B)`$: Gegeben die Daten $`B`$, wie wahrscheinlich ist die Klasse
  $`A`$? (Posterior)

In der Medizin hat sucht man i.d.R. die Ursache f√ºr beobachtete
Symptome:
``` math
P(\text{Ursache}|\text{Symptome}) = \frac{P(\text{Symptome}|\text{Ursache})P(\text{Ursache})}{P(\text{Symptome})}
```

Aus der A-priori-Wahrscheinlichkeit f√ºr bestimmte Krankheiten und der
Likelihood der Symptome (wie wahrscheinlich sind Symptome, gegeben eine
Krankheit) kann man die Wahrscheinlichkeit f√ºr das Vorliegen einer
Erkrankung gegeben bestimmte Symptome berechnen.

## Beispiel Bayes

- Bei Arthrose wird in 80 Prozent der F√§lle ein steifes Gelenk
  beobachtet
- Eine von 10.000 Personen hat Arthrose
- Eine von 10 Personen hat ein steifes Gelenk

=\> Ich habe ein steifes Gelenk. Habe ich Arthrose?

- Gegeben: $`P(A) = 0.0001,   P(S) = 0.1,   P(S|A) = 0.8`$
- Gesucht: $`P(A|S)`$

``` math
P(A|S) = \frac{P(S|A)P(A)}{P(S)} = \frac{0.8 \times 0.0001}{0.1} = 0.0008 = 0.08\%
```

Wenn ein steifes Gelenk vorliegt, ist die Wahrscheinlichkeit, dann an
Arthrose erkrankt zu sein, bei nur 0.08%. Kein Grund zur Sorge in diesem
Fall :-)

=\> Wie wahrscheinlich ist ein steifes Gelenk ohne Arthrose, also
$`P(S|\neg A`$)?

Mit Marginalisierung: $`P(S) = P(S|A)P(A) + P(S|\neg A)P(\neg A)`$, d.h.
$`0.1 = 0.8 \times 0.0001 + P(S|\neg A) \times (1-0.0001)`$, d.h.
$`P(S|\neg A) = 0.0999`$

In knapp 10 Prozent der F√§lle w√ºrde man im obigen Beispiel bei der
Diagnose ‚Äúkeine Arthrose‚Äù ein steifes Gelenk beobachten.

**Hinweis**: Die genannten Zahlen und Zusammenh√§nge sind rein fiktional
und sollen lediglich zur Veranschaulichung der Bayes-Regel dienen!

Schauen Sie sich auch das Beispiel 7.9 in ([Ertel 2017](#ref-Ertel2017),
Ex. 7.9, S. 135) an!

## Unabh√§ngige Ereignisse

- $`P(\text{Halsschmerzen},\text{ Regen}) = P(\text{Regen }|\text{ Halsschmerzen})P(\text{Halsschmerzen})`$
- $`P(\text{Regen }|\text{ Halsschmerzen}) = \text{ ?? }`$
  $`= P(\text{Regen})`$

<!-- -->

- Zwei Ereignisse $`A`$ und $`B`$ sind **unabh√§ngig**, wenn

  =\> $`P(A,B) = P(A|B)P(B) = P(A)P(B)`$

``` math
P(A|B) = P(A)
```

Dies kann man verallgemeinern (**bedingte Unabh√§ngigkeit**):

> $`X`$ und $`Y`$ sind *bedingt unabh√§ngig* (gegeben $`Z`$), wenn
> $`P(X|Y,Z) = P(X|Z)`$ bzw. $`P(Y|X,Z) = P(Y|Z)`$

Daraus folgt:

``` math
P(X,Y|Z) = P(X|Y,Z)P(Y|Z) = P(X|Z)P(Y|Z)
```

## Wrap-Up

- Grundlagen der Wahrscheinlichkeitstheorie
  - Elementarereignisse und Wahrscheinlichkeit
  - Rechenregeln
  - Bedingte Wahrscheinlichkeit und Verbundwahrscheinlichkeit
  - Marginalisierung
  - (Bedingte) Unabh√§ngigkeit
  - Bayes‚Äôsche Regel

## üìñ Zum Nachlesen

- Russell und Norvig ([2020](#ref-Russell2020)): Kapitel 12
- Ertel ([2017](#ref-Ertel2017)): Abschnitt 7.1

------------------------------------------------------------------------

> [!TIP]
>
> <details>
>
> <summary><strong>‚úÖ Lernziele</strong></summary>
>
> - k2: Elementarereignisse und Wahrscheinlichkeit
> - k2: Bedingte Wahrscheinlichkeit und Verbundwahrscheinlichkeit
> - k2: (Bedingte) Unabh√§ngigkeit
> - k3: Rechenregeln
> - k3: Marginalisierung
> - k3: Bayes‚Äôsche Regel
>
> </details>
>
> <details>
>
> <summary><strong>üß© Quizzes</strong></summary>
>
> - [Selbsttest Wahrscheinlichkeiten
>   (ILIAS)](https://www.hsbi.de/elearning/goto.php?target=tst_1106587&client_id=FH-Bielefeld)
>
> </details>

------------------------------------------------------------------------

> [!NOTE]
>
> <details>
>
> <summary><strong>üëÄ Quellen</strong></summary>
>
> <div id="refs" class="references csl-bib-body hanging-indent"
> entry-spacing="0">
>
> <div id="ref-Ertel2017" class="csl-entry">
>
> Ertel, W. 2017. *Introduction to Artificial Intelligence*. 2nd
> edition. Springer. <https://doi.org/10.1007/978-3-319-58487-4>.
>
> </div>
>
> <div id="ref-Russell2020" class="csl-entry">
>
> Russell, S., und P. Norvig. 2020. *Artificial Intelligence: A Modern
> Approach*. 4th Edition. Pearson. <http://aima.cs.berkeley.edu>.
>
> </div>
>
> </div>
>
> </details>

------------------------------------------------------------------------

<img src="https://licensebuttons.net/l/by-sa/4.0/88x31.png" width="10%">

Unless otherwise noted, this work is licensed under CC BY-SA 4.0.

<blockquote><p><sup><sub><strong>Last modified:</strong> 6672880 (markdown: switch to leaner yaml header (#438), 2025-08-09)<br></sub></sup></p></blockquote>
